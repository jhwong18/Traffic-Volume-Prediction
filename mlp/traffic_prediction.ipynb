{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "This dataset provides hourly traffic volume for a city, including features indicating holidays and weather conditions.\n",
    "The files used here span from 1st January 2013 to 31st December 2013. The data is acquired from the Minnesota Department of Transportation (www.dot.state.mn.us). The features are shown below:\n",
    "\n",
    "Attributes:\n",
    "- `holiday`: US national and regional holidays\n",
    "- `temp`: average temperature in Kelvin (K)\n",
    "- `rain_1h`: rain that occured in the hour (mm)\n",
    "- `snow_1h`: snow that occured in the hour (mm)\n",
    "- `clouds_all`: percentage of cloud cover\n",
    "- `weather main`: textual description of current weather\n",
    "- `weather_description`: longer textual description of current weather\n",
    "- `date_time`: hour of the data collected in local time\n",
    "\n",
    "Attribute (Output):\n",
    "- `traffic_volume`: hourly I-94 reported westbound traffic volume\n",
    "\n",
    "\n",
    "\n",
    "## Objective\n",
    "We would like to predict the traffic volume based on the attributes mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Years Day</td>\n",
       "      <td>263.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>263.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>264.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>Snow</td>\n",
       "      <td>heavy snow</td>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>263.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>263.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0  New Years Day  263.49      0.0        0          58       Clouds   \n",
       "1           None  263.78      0.0        0          40       Clouds   \n",
       "2           None  264.16      0.0        0          75         Snow   \n",
       "3           None  263.95      0.0        0          90       Clouds   \n",
       "4           None  263.65      0.0        0          90       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0       broken clouds  2013-01-01 00:00:00            1439  \n",
       "1    scattered clouds  2013-01-01 01:00:00            1502  \n",
       "2          heavy snow  2013-01-01 02:00:00             933  \n",
       "3     overcast clouds  2013-01-01 03:00:00             576  \n",
       "4     overcast clouds  2013-01-01 04:00:00             372  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import datetime as dt \n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "url=\"https://aisgaiap.blob.core.windows.net/aiap5-assessment-data/traffic_data.csv\"\n",
    "s=requests.get(url).content\n",
    "dat=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "dat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "dat['date_time'] = pd.to_datetime(dat['date_time'])\n",
    "\n",
    "def when_was_it(x):\n",
    "    if x.hour >= 5 and x.hour < 10:\n",
    "        return \"Morning Rush (5-10)\"\n",
    "    elif x.hour >= 10 and x.hour < 15:\n",
    "        return \"Office Hours (10-15)\"\n",
    "    elif x.hour >= 15 and x.hour < 19:\n",
    "        return \"Afternoon Rush (15-19)\"\n",
    "    elif x.hour >= 19 and x.hour < 23:\n",
    "        return \"Evening (19-23)\"\n",
    "    else:\n",
    "        return \"Night (23-5)\"\n",
    "\n",
    "\n",
    "# Create a new column for categories of time\n",
    "dat['Time'] = dat['date_time'].apply(when_was_it)\n",
    "#dat['Time']\n",
    "\n",
    "\n",
    "# Create a new column for month\n",
    "def get_month(x):\n",
    "    if x.month == 1:\n",
    "        return \"January\"\n",
    "    if x.month == 2:\n",
    "        return \"February\"\n",
    "    if x.month == 3:\n",
    "        return \"March\"\n",
    "    if x.month == 4:\n",
    "        return \"April\"\n",
    "    if x.month == 5:\n",
    "        return \"May\"\n",
    "    if x.month == 6:\n",
    "        return \"June\"\n",
    "    if x.month == 7:\n",
    "        return \"July\"\n",
    "    if x.month == 8:\n",
    "        return \"August\"\n",
    "    if x.month == 9:\n",
    "        return \"September\"\n",
    "    if x.month == 10:\n",
    "        return \"October\"\n",
    "    if x.month == 11:\n",
    "        return \"November\"\n",
    "    if x.month == 12:\n",
    "        return \"December\"\n",
    "dat['Month'] = dat['date_time'].apply(get_month)\n",
    "\n",
    "\n",
    "def is_holiday(x):\n",
    "    if x != \"None\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "dat['Is_holiday'] = dat['holiday'].apply(is_holiday)\n",
    "\n",
    "\n",
    "\n",
    "dat['is_weekday'] = dat['date_time'].dt.day_name()\n",
    "def is_weekday(x):\n",
    "    if (x == \"Saturday\") or (x == \"Sunday\") :\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "dat['is_weekday'] = dat['is_weekday'].apply(is_weekday)\n",
    "dat = dat.drop(['holiday','snow_1h','clouds_all','weather_description','date_time'],axis=1)\n",
    "dat = dat[['Is_holiday', 'temp','rain_1h','weather_main','Time','is_weekday','Month','traffic_volume']]\n",
    "#dat.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding weather_main\n",
      "Encoding Time\n",
      "Encoding Month\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding for Month, Time and Weather\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# For each categorical column\n",
    "# We fit a label encoder, transform our column and \n",
    "# add it to our new dataframe\n",
    "label_encoders = {}\n",
    "dat_processed = dat[['weather_main','Time','Month']]\n",
    "cat_columns = ['weather_main','Time','Month']\n",
    "for col in cat_columns:\n",
    "    print(\"Encoding {}\".format(col))\n",
    "    new_le = LabelEncoder()\n",
    "    dat_processed[col] = new_le.fit_transform(dat[col])\n",
    "    label_encoders[col] = new_le\n",
    "#dat_processed\n",
    "\n",
    "cat_columns_idx = [dat_processed.columns.get_loc(col) \n",
    "                   for col in cat_columns]\n",
    "#cat_columns_idx\n",
    "ohe = OneHotEncoder(categorical_features=cat_columns_idx, \n",
    "                    sparse=False, handle_unknown=\"ignore\")\n",
    "dat_processed_np = ohe.fit_transform(dat_processed)\n",
    "dat_processed_np = pd.DataFrame(dat_processed_np)\n",
    "\n",
    "dat1 = dat.drop(['weather_main','Time','Month'], axis = 1)\n",
    "dat1 = pd.concat([dat_processed_np,dat1],axis=1)\n",
    "#dat1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>Is_holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>is_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>264.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>279.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>266.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>284.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>296.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9     ...       21   22  \\\n",
       "7868  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0     ...      0.0  0.0   \n",
       "2223  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     ...      0.0  0.0   \n",
       "1567  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0     ...      0.0  1.0   \n",
       "3780  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     ...      0.0  0.0   \n",
       "6468  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     ...      0.0  0.0   \n",
       "\n",
       "       23   24   25   26  Is_holiday    temp  rain_1h  is_weekday  \n",
       "7868  0.0  0.0  0.0  0.0           0  264.46      0.0           1  \n",
       "2223  0.0  0.0  0.0  0.0           0  279.84      0.0           1  \n",
       "1567  0.0  0.0  0.0  0.0           0  266.83      0.0           1  \n",
       "3780  1.0  0.0  0.0  0.0           0  284.23      0.0           1  \n",
       "6468  0.0  0.0  0.0  1.0           0  296.41      0.0           1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dat1.drop(['traffic_volume'], axis = 1)\n",
    "Y = dat1['traffic_volume']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling of the features: rain_1h and temperature\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #Importing Scaler\n",
    "\n",
    "X_train1 = X_train.iloc[:,].values\n",
    "X_test1 = X_test.iloc[:,].values\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_x.fit_transform(X_train1)\n",
    "X_test_scaled = scaler_x.fit_transform(X_test1)\n",
    "X_train_scaled = pd.DataFrame(X_train1)\n",
    "X_test_scaled = pd.DataFrame(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression linear model intercept: -133667737654027.75\n",
      "Linear regression linear model coeff:\n",
      "[ 1.33667738e+14  1.33667738e+14  1.33667738e+14  1.33667738e+14\n",
      "  1.33667738e+14  1.33667738e+14  1.33667738e+14  1.33667738e+14\n",
      "  1.33667738e+14  1.33667738e+14  1.69398622e+03 -7.03173809e+02\n",
      "  5.51794012e+02 -2.73916282e+03  1.19702817e+03  4.19678196e+01\n",
      "  6.57992421e+01 -1.83953518e+02  7.72322698e+00 -7.21308830e+01\n",
      " -1.14670401e+02  6.67290081e+00  4.41128801e+01 -8.09711365e+01\n",
      "  1.99421261e+01  2.20489966e+02  4.47877783e+01 -1.81330408e+02\n",
      "  1.03263928e+01 -2.61867473e+01  1.00408581e+03]\n",
      "R-squared score (training): 0.743\n",
      "R-squared score (test): 0.765\n",
      "Number of non-zero features: 31\n",
      "RMSE score (test): 988.830\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the Linear Regression coefficients and Feature Normalization \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linridge = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Linear regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('Linear regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "print('RMSE score (test): {:.3f}'\n",
    "     .format(rmse(linridge.predict(X_test_scaled),y_test)))\n",
    "linreg_accuracy = rmse(linridge.predict(X_test_scaled),y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge regression linear model intercept: -118.99342249159781\n",
      "ridge regression linear model coeff:\n",
      "[   25.20417086    16.31175789    24.40011651   -31.13408608\n",
      "  -141.88065671   -55.40151334   -14.71787462   -68.45911626\n",
      "   249.9412792     -4.26407745  1693.11618728  -702.85727622\n",
      "   551.57431009 -2738.33902062  1196.50579947    41.99188669\n",
      "    65.62882138  -183.8074342      7.68370921   -71.78307846\n",
      "  -114.70378459     6.62568854    44.13516555   -80.72143305\n",
      "    20.25591587   220.13333797    44.56120509  -172.47508041\n",
      "    10.35586523   -26.04684926  1003.64656512]\n",
      "R-squared score (training): 0.743\n",
      "R-squared score (test): 0.765\n",
      "Number of non-zero features: 31\n",
      "RMSE score (test): 988.841\n",
      "Ridge regression: effect of alpha regularization parameter\n",
      "\n",
      "Alpha = 0.00\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.00\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8529\n",
      "\n",
      "Alpha = 0.10\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.10\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8290\n",
      "\n",
      "Alpha = 0.20\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.20\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8320\n",
      "\n",
      "Alpha = 0.30\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.30\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8350\n",
      "\n",
      "Alpha = 0.40\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.40\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8380\n",
      "\n",
      "Alpha = 0.50\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.50\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8410\n",
      "\n",
      "Alpha = 0.60\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.60\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8441\n",
      "\n",
      "Alpha = 0.70\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.70\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8472\n",
      "\n",
      "Alpha = 0.80\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.80\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8503\n",
      "\n",
      "Alpha = 0.90\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 0.90\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8534\n",
      "\n",
      "Alpha = 1.00\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7427, r-squared test: 0.7651\n",
      "\n",
      "Alpha = 1.00\n",
      "num abs(coeff) > 1.0: 31, rmse training: 988.8565\n",
      "\n",
      "Alpha = 10.00\n",
      "num abs(coeff) > 1.0: 30, r-squared training: 0.7426, r-squared test: 0.7649\n",
      "\n",
      "Alpha = 10.00\n",
      "num abs(coeff) > 1.0: 30, rmse training: 989.2130\n",
      "\n",
      "Alpha = 20.00\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7425, r-squared test: 0.7646\n",
      "\n",
      "Alpha = 20.00\n",
      "num abs(coeff) > 1.0: 31, rmse training: 989.7751\n",
      "\n",
      "Alpha = 50.00\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7417, r-squared test: 0.7634\n",
      "\n",
      "Alpha = 50.00\n",
      "num abs(coeff) > 1.0: 31, rmse training: 992.3813\n",
      "\n",
      "Alpha = 100.00\n",
      "num abs(coeff) > 1.0: 31, r-squared training: 0.7392, r-squared test: 0.7601\n",
      "\n",
      "Alpha = 100.00\n",
      "num abs(coeff) > 1.0: 31, rmse training: 999.2314\n",
      "\n",
      "Alpha = 1000.00\n",
      "num abs(coeff) > 1.0: 29, r-squared training: 0.6172, r-squared test: 0.6294\n",
      "\n",
      "Alpha = 1000.00\n",
      "num abs(coeff) > 1.0: 29, rmse training: 1241.8913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the Ridge Regression coefficients and Feature Normalization \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "linridge = Ridge(alpha=0.5).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))\n",
    "\n",
    "print('RMSE score (test): {:.3f}'\n",
    "     .format(rmse(linridge.predict(X_test_scaled),y_test)))\n",
    "\n",
    "\n",
    "# Choosing the optimal value of Alpha in ridge regression\n",
    "ridge_accuracy_arr = np.array([0])\n",
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1, 10, 20, 50, 100, 1000]:\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linridge.score(X_train_scaled, y_train)\n",
    "    r2_test = linridge.score(X_test_scaled, y_test)\n",
    "    rmse_test = rmse(linridge.predict(X_test_scaled),y_test)\n",
    "    ridge_accuracy_arr = np.append(ridge_accuracy_arr, rmse_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.4f}, r-squared test: {:.4f}\\n'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "rmse training: {:.4f}\\n'\n",
    "         .format(this_alpha, num_coeff_bigger, rmse_test))\n",
    "\n",
    "ridge_accuracy = np.amin(ridge_accuracy_arr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, None],\n",
      " 'max_features': ['auto'],\n",
      " 'min_samples_leaf': [1, 2, 3, 4],\n",
      " 'min_samples_split': [2, 3, 5, 7, 9],\n",
      " 'n_estimators': [5,\n",
      "                  15,\n",
      "                  25,\n",
      "                  35,\n",
      "                  46,\n",
      "                  56,\n",
      "                  66,\n",
      "                  76,\n",
      "                  87,\n",
      "                  97,\n",
      "                  107,\n",
      "                  117,\n",
      "                  128,\n",
      "                  138,\n",
      "                  148,\n",
      "                  158,\n",
      "                  169,\n",
      "                  179,\n",
      "                  189,\n",
      "                  200]}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 0)\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.grid_search import GridSearchCV  \n",
    "\n",
    "# To use GridSearchCV, we first need to create a parameter grid to sample from during fitting:\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 200, num = 20)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 15, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5,7,9]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3,4]\n",
    "# Method of selecting samples for training each tree\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "pprint(random_grid)\n",
    "\n",
    "# Random Search Training\n",
    "# Now, we instantiate the random search and fit it like any Scikit-Learn model:\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "# rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv =3, verbose=2)\n",
    "# Fit the random search model\n",
    "# rf_random.fit(X_train_scaled, y_train)\n",
    "# rf_random.best_params_\n",
    "\n",
    "# Output from Hyper-parameter tuning\n",
    "# Parallel(n_jobs=1)]: Done 13200 out of 13200 | elapsed: 158.3min finished\n",
    "# Out[8]:\n",
    "# {'max_depth': 11,\n",
    "#  'max_features': 'auto',\n",
    "#  'min_samples_leaf': 2,\n",
    "#  'min_samples_split': 5,\n",
    "#  'n_estimators': 117}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried to tune the following set of hyperparameters:\n",
    "- 'n_estimators' = number of trees in the foreset\n",
    "- 'max_features' = max number of features considered for splitting a node\n",
    "- 'max_depth' = max number of levels in each decision tree\n",
    "- 'min_samples_split' = min number of data points placed in a node before the node is split\n",
    "- 'min_samples_leaf' = min number of data points allowed in a leaf node\n",
    "- 'bootstrap' = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor (Post-tuning)\n",
      "Model Performance\n",
      "RMSE: 781.4653\n",
      "Random Forest Regressor (Pre-tuning)\n",
      "Model Performance\n",
      "RMSE: 832.4779\n",
      "Improvement of 6.13%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV  \n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = np.sum((predictions - test_labels)**2)\n",
    "    rmse = np.sqrt(errors/test_features.shape[0])\n",
    "    print('Model Performance')\n",
    "    print('RMSE: {:0.4f}'.format(rmse))\n",
    "    return rmse\n",
    "\n",
    "print('Random Forest Regressor (Post-tuning)')\n",
    "best_rf_model = RandomForestRegressor(n_estimators=117, max_features='auto',max_depth=11,min_samples_split=5,min_samples_leaf=2)\n",
    "best_rf_model.fit(X_train_scaled, y_train)\n",
    "random_accuracy = evaluate(best_rf_model, X_test_scaled, y_test)\n",
    "random_accuracy\n",
    "\n",
    "print('Random Forest Regressor (Pre-tuning)')\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "base_model.fit(X_train_scaled, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test_scaled, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( -100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted Regression Trees\n",
    "\n",
    "import xgboost\n",
    "from xgboost import plot_importance\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "\n",
    "\n",
    "#for tuning parameters\n",
    "# param_grid = {\n",
    "#    'colsample_bytree':[0.4,0.6],\n",
    "#    'gamma':[0.05,0.1],\n",
    "#    'min_child_weight':[1.5,6],\n",
    "#    'learning_rate':[0.1,0.07],\n",
    "#    'max_depth':[int(x) for x in np.linspace(8, 13, num = 6)],\n",
    "#    'n_estimators':[int(x) for x in np.linspace(start = 50, stop = 150, num = 5)],\n",
    "#    'reg_alpha':[1e-5,  0.5],\n",
    "#    'reg_lambda':[1e-5, 0.45],\n",
    "#    'subsample':[0.6,0.95]  \n",
    "# }\n",
    "\n",
    "                    \n",
    "# xgb_model = xgboost.XGBRegressor(learning_rate =0.1, n_estimators=10, max_depth=5,\n",
    "#     min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=6, scale_pos_weight=1, seed=0)\n",
    "\n",
    "# gsearch1 = GridSearchCV(estimator = xgb_model, param_grid = param_grid, n_jobs = 6, iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "# gsearch1.fit(X_train_scaled, y_train)\n",
    "# print (gsearch1.grid_scores_)\n",
    "# print('best params')\n",
    "# print (gsearch1.best_params_)\n",
    "# print('best score')\n",
    "# print (gsearch1.best_score_)\n",
    "\n",
    "# Output from Hyper-parameter tuning\n",
    "# [Parallel(n_jobs=6)]: Done 11520 out of 11520 | elapsed: 59.2min finished\n",
    "# best_xgb_model = xgboost.XGBRegressor(colsample_bytree=0.6,\n",
    "#                  gamma=0.05,                 \n",
    "#                  learning_rate=0.07,\n",
    "#                  max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "#                  n_estimators=100,                                                                    \n",
    "#                  reg_alpha=1e-05,\n",
    "#                  reg_lambda=0.45,\n",
    "#                  subsample=0.95)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0,'Is_Mist'),\n",
       " Text(0,0,'Is_Clear'),\n",
       " Text(0,0,'Is_Clouds'),\n",
       " Text(0,0,'Rainfall 1hour'),\n",
       " Text(0,0,'Temperature')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print (gsearch1.best_params_)\n",
    "best_xgb_model = xgboost.XGBRegressor(colsample_bytree=0.6,\n",
    "                 gamma=0.05,                 \n",
    "                 learning_rate=0.07,\n",
    "                 max_depth=8,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=100,                                                                    \n",
    "                 reg_alpha=1e-05,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.95)\n",
    "best_xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "plot_importance(best_xgb_model, max_num_features = 5).set_yticklabels(['Is_Mist','Is_Clear','Is_Clouds','Rainfall 1hour','Temperature'])  # top most important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor (Post-tuning)\n",
      "Model Performance\n",
      "RMSE: 775.4962\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "best_xgb_model = xgboost.XGBRegressor(colsample_bytree=0.6,\n",
    "                 gamma=0.05,                 \n",
    "                 learning_rate=0.07,\n",
    "                 max_depth=8,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=100,                                                                    \n",
    "                 reg_alpha=1e-05,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.95)\n",
    "best_xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('XGBoost Regressor (Post-tuning)')\n",
    "XGB_accuracy = evaluate(best_xgb_model, X_test_scaled, y_test)\n",
    "#XGB_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Logistic Regression\n",
      "RMSE: 988.8300\n",
      "Model Performance for Ridge Regression\n",
      "RMSE: 988.8290\n",
      "Model Performance for Random Forest\n",
      "RMSE: 781.4653\n",
      "Model Performance for XGBoost\n",
      "RMSE: 775.4962\n"
     ]
    }
   ],
   "source": [
    "# Results of trained models\n",
    "\n",
    "\n",
    "# logistic Regression\n",
    "print('Model Performance for Logistic Regression')\n",
    "print('RMSE: {:0.4f}'.format(linreg_accuracy))\n",
    "print('Model Performance for Ridge Regression')\n",
    "print('RMSE: {:0.4f}'.format(ridge_accuracy)) \n",
    "print('Model Performance for Random Forest')\n",
    "print('RMSE: {:0.4f}'.format(random_accuracy))\n",
    "print('Model Performance for XGBoost')\n",
    "print('RMSE: {:0.4f}'.format(XGB_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models trained\n",
    "\n",
    "- Performance for Logistic Regression\n",
    "RMSE: 988.8300\n",
    "- Performance for Ridge Regression\n",
    "RMSE: 988.8290\n",
    "- Performance for Random Forest\n",
    "RMSE: 781.0434\n",
    "- Performance for XGBoost: RMSE: 775.4962\n",
    "\n",
    "XGBoost is the best performing model for the prediction of traffic volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
